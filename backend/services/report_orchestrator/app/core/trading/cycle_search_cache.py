"""
Cycle Search Cache - å‘¨æœŸå†…æœç´¢ç»“æœå…±äº«

åœ¨å•ä¸ªåˆ†æå‘¨æœŸå†…è·¨ Agent å…±äº«æœç´¢ç»“æœï¼Œé¿å…é‡å¤è°ƒç”¨ Tavily APIã€‚

Context Engineering P0 ç­–ç•¥ï¼š
- Agent 1 æœç´¢ "Bitcoin news today" â†’ ç¼“å­˜ç»“æœ
- Agent 2 æœç´¢ "BTC news today" â†’ è¯­ä¹‰åŒ¹é…ï¼Œå¤ç”¨ç»“æœ
- å‘¨æœŸç»“æŸåæ¸…ç©ºç¼“å­˜
"""

import hashlib
import logging
import re
from typing import Any, Dict, Optional, Callable, Set
from datetime import datetime
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)


class CycleSearchCache:
    """
    å•ä¸ªåˆ†æå‘¨æœŸå†…çš„æœç´¢ç»“æœå…±äº«ç¼“å­˜
    
    ç‰¹ç‚¹ï¼š
    1. ç²¾ç¡®åŒ¹é…ï¼šå®Œå…¨ç›¸åŒçš„æŸ¥è¯¢ç›´æ¥å¤ç”¨
    2. è¯­ä¹‰ç›¸ä¼¼åŒ¹é…ï¼š80% ç›¸ä¼¼åº¦çš„æŸ¥è¯¢è€ƒè™‘å¤ç”¨
    3. å‘¨æœŸå†…æœ‰æ•ˆï¼šåˆ†æå‘¨æœŸç»“æŸåè‡ªåŠ¨æ¸…ç©º
    4. ç»Ÿè®¡åŠŸèƒ½ï¼šè·Ÿè¸ªå‘½ä¸­ç‡å’ŒèŠ‚çœçš„è°ƒç”¨æ¬¡æ•°
    """
    
    SIMILARITY_THRESHOLD = 0.75  # è¯­ä¹‰ç›¸ä¼¼åº¦é˜ˆå€¼
    
    def __init__(self):
        self._cache: Dict[str, Dict[str, Any]] = {}  # query -> result
        self._normalized_index: Dict[str, str] = {}  # normalized_query -> original_query
        self._stats = {
            "exact_hits": 0,
            "semantic_hits": 0,
            "misses": 0,
            "api_calls_saved": 0
        }
        self._cycle_id: Optional[str] = None
        self._start_time: Optional[datetime] = None
    
    def start_cycle(self, cycle_id: str = None):
        """å¼€å§‹æ–°çš„åˆ†æå‘¨æœŸï¼Œæ¸…ç©ºç¼“å­˜"""
        self._cache.clear()
        self._normalized_index.clear()
        self._cycle_id = cycle_id or datetime.now().strftime("%Y%m%d_%H%M%S")
        self._start_time = datetime.now()
        logger.info(f"[CycleSearchCache] Started new cycle: {self._cycle_id}")
    
    def end_cycle(self) -> Dict[str, Any]:
        """ç»“æŸåˆ†æå‘¨æœŸï¼Œè¿”å›ç»Ÿè®¡ä¿¡æ¯"""
        stats = self.get_stats()
        logger.info(
            f"[CycleSearchCache] Cycle {self._cycle_id} ended. "
            f"Hits: {stats['total_hits']}, Misses: {stats['misses']}, "
            f"API calls saved: {stats['api_calls_saved']}"
        )
        return stats
    
    def _normalize_query(self, query: str) -> str:
        """è§„èŒƒåŒ–æŸ¥è¯¢å­—ç¬¦ä¸²ç”¨äºåŒ¹é…"""
        # è½¬å°å†™
        normalized = query.lower().strip()
        # ç§»é™¤å¤šä½™ç©ºæ ¼
        normalized = re.sub(r'\s+', ' ', normalized)
        # ç§»é™¤å¸¸è§åœç”¨è¯
        stop_words = {'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for'}
        words = normalized.split()
        words = [w for w in words if w not in stop_words]
        return ' '.join(words)
    
    def _calculate_similarity_string(self, query1: str, query2: str) -> float:
        """è®¡ç®—ä¸¤ä¸ªæŸ¥è¯¢çš„å­—ç¬¦ä¸²ç›¸ä¼¼åº¦ (0-1) - åå¤‡æ–¹æ¡ˆ"""
        norm1 = self._normalize_query(query1)
        norm2 = self._normalize_query(query2)
        return SequenceMatcher(None, norm1, norm2).ratio()
    
    async def _find_similar_query(self, query: str) -> Optional[str]:
        """
        æŸ¥æ‰¾è¯­ä¹‰ç›¸ä¼¼çš„å·²ç¼“å­˜æŸ¥è¯¢
        
        ğŸ†• ä½¿ç”¨ Gemini Embedding è¿›è¡ŒçœŸæ­£çš„è¯­ä¹‰åŒ¹é…
        å¦‚æœ API ä¸å¯ç”¨åˆ™é€€å›åˆ°å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        """
        if not self._cache:
            return None
        
        normalized = self._normalize_query(query)
        
        # å…ˆæ£€æŸ¥è§„èŒƒåŒ–åçš„ç²¾ç¡®åŒ¹é…
        if normalized in self._normalized_index:
            return self._normalized_index[normalized]
        
        # å°è¯•ä½¿ç”¨ Gemini Embedding è¿›è¡Œè¯­ä¹‰åŒ¹é…
        try:
            from app.core.trading.gemini_embedding import get_embedding_service
            
            embedding_service = get_embedding_service()
            
            if embedding_service.api_key:
                # ä½¿ç”¨ Gemini Embedding è¿›è¡ŒçœŸæ­£çš„è¯­ä¹‰åŒ¹é…
                cached_queries = list(self._cache.keys())
                result = await embedding_service.find_most_similar(
                    query=query,
                    candidates=cached_queries,
                    threshold=self.SIMILARITY_THRESHOLD
                )
                
                if result:
                    best_match, score = result
                    logger.info(
                        f"[CycleSearchCache] ğŸ§  Gemini semantic match: "
                        f"'{query[:40]}...' â‰ˆ '{best_match[:40]}...' (sim={score:.3f})"
                    )
                    return best_match
                
                return None
                
        except Exception as e:
            logger.warning(f"[CycleSearchCache] Gemini embedding failed, falling back to string similarity: {e}")
        
        # åå¤‡æ–¹æ¡ˆï¼šä½¿ç”¨å­—ç¬¦ä¸²ç›¸ä¼¼åº¦
        best_match = None
        best_score = 0
        
        for cached_query in self._cache.keys():
            score = self._calculate_similarity_string(query, cached_query)
            if score > best_score and score >= self.SIMILARITY_THRESHOLD:
                best_match = cached_query
                best_score = score
        
        if best_match:
            logger.debug(
                f"[CycleSearchCache] String match (fallback): '{query[:50]}...' â‰ˆ '{best_match[:50]}...' "
                f"(similarity: {best_score:.2f})"
            )
        
        return best_match
    
    async def get_or_search(
        self, 
        query: str, 
        search_fn: Callable,
        **search_params
    ) -> Dict[str, Any]:
        """
        è·å–ç¼“å­˜ç»“æœæˆ–æ‰§è¡Œæœç´¢
        
        Args:
            query: æœç´¢æŸ¥è¯¢
            search_fn: æœç´¢å‡½æ•° (async)
            **search_params: æœç´¢å‚æ•°
        
        Returns:
            æœç´¢ç»“æœ (æ¥è‡ªç¼“å­˜æˆ–æ–°æœç´¢)
        """
        # 1. ç²¾ç¡®åŒ¹é…
        if query in self._cache:
            self._stats["exact_hits"] += 1
            self._stats["api_calls_saved"] += 1
            logger.info(f"[CycleSearchCache] EXACT HIT: '{query[:50]}...'")
            result = self._cache[query].copy()
            result["_cache_status"] = "exact_hit"
            return result
        
        # 2. è¯­ä¹‰ç›¸ä¼¼åŒ¹é… (ä½¿ç”¨ Gemini Embedding)
        similar_query = await self._find_similar_query(query)
        if similar_query:
            self._stats["semantic_hits"] += 1
            self._stats["api_calls_saved"] += 1
            logger.info(f"[CycleSearchCache] SEMANTIC HIT: '{query[:50]}...' â†’ reusing '{similar_query[:50]}...'")
            result = self._cache[similar_query].copy()
            result["_cache_status"] = "semantic_hit"
            result["_original_query"] = similar_query
            return result
        
        # 3. ç¼“å­˜æœªå‘½ä¸­ï¼Œæ‰§è¡Œæœç´¢
        self._stats["misses"] += 1
        logger.info(f"[CycleSearchCache] MISS: '{query[:50]}...' - calling API")
        
        result = await search_fn(query, **search_params)
        
        # 4. ç¼“å­˜ç»“æœ
        if result and isinstance(result, dict):
            result["_cached_at"] = datetime.now().isoformat()
            result["_cache_status"] = "fresh"
            self._cache[query] = result
            self._normalized_index[self._normalize_query(query)] = query
        
        return result
    
    def get_stats(self) -> Dict[str, Any]:
        """è·å–ç¼“å­˜ç»Ÿè®¡"""
        total_hits = self._stats["exact_hits"] + self._stats["semantic_hits"]
        total_requests = total_hits + self._stats["misses"]
        hit_rate = (total_hits / total_requests * 100) if total_requests > 0 else 0
        
        return {
            "cycle_id": self._cycle_id,
            "exact_hits": self._stats["exact_hits"],
            "semantic_hits": self._stats["semantic_hits"],
            "total_hits": total_hits,
            "misses": self._stats["misses"],
            "hit_rate": f"{hit_rate:.1f}%",
            "api_calls_saved": self._stats["api_calls_saved"],
            "cached_queries": len(self._cache),
            "duration": str(datetime.now() - self._start_time) if self._start_time else None
        }
    
    def get_cached_queries(self) -> Set[str]:
        """è·å–æ‰€æœ‰å·²ç¼“å­˜çš„æŸ¥è¯¢"""
        return set(self._cache.keys())


# å…¨å±€å®ä¾‹ (å‘¨æœŸå†…å…±äº«)
_cycle_search_cache: Optional[CycleSearchCache] = None


def get_cycle_search_cache() -> CycleSearchCache:
    """è·å–å‘¨æœŸæœç´¢ç¼“å­˜çš„å…¨å±€å®ä¾‹"""
    global _cycle_search_cache
    if _cycle_search_cache is None:
        _cycle_search_cache = CycleSearchCache()
    return _cycle_search_cache


def reset_cycle_search_cache():
    """é‡ç½®å…¨å±€ç¼“å­˜å®ä¾‹ (ç”¨äºæµ‹è¯•)"""
    global _cycle_search_cache
    _cycle_search_cache = None
