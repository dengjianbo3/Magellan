"""
Enhanced Tools for Roundtable Discussion Agents - Phase 1

Contains:
1. ChinaMarketDataTool - China market data (A-shares/HK stocks)
2. QichaChaTool - Company info lookup
3. GitHubAnalyzerTool - GitHub project analysis
4. PatentSearchTool - Patent search
5. SentimentMonitorTool - Sentiment monitoring
"""
import os
import httpx
import asyncio
from typing import Any, Dict, List, Optional
from datetime import datetime, timedelta
from .tool import Tool


# ==================== 1. China Market Data Tool ====================

class ChinaMarketDataTool(Tool):
    """
    China Market Data Tool

    Supports A-share and HK stock data queries through multiple data sources:
    - Eastmoney
    - Sina Finance
    - 10jqka (backup)

    Features:
    - Real-time quotes
    - Historical K-lines
    - Financial statements
    - Company info
    """

    def __init__(self):
        super().__init__(
            name="china_market_data",
            description="""Get China A-share and Hong Kong stock market data.

Features:
- Real-time stock prices and quotes
- Historical K-line data
- Financial statements (balance sheet, income statement, cash flow)
- Company basic info

Supported markets:
- A-shares (Shanghai: SH, Shenzhen: SZ, e.g., 600519.SH, 000001.SZ)
- HK stocks (HK, e.g., 00700.HK, 09988.HK)

Examples:
- Query Kweichow Moutai: symbol="600519" or "600519.SH"
- Query Tencent: symbol="00700" or "00700.HK"
"""
        )
        # ä¸œæ–¹è´¢å¯ŒAPIé…ç½®
        self.eastmoney_quote_url = "http://push2.eastmoney.com/api/qt/stock/get"
        self.eastmoney_kline_url = "http://push2his.eastmoney.com/api/qt/stock/kline/get"
        self.eastmoney_finance_url = "http://emweb.securities.eastmoney.com/PC_HSF10/NewFinanceAnalysis"

    def _detect_market(self, symbol: str) -> tuple:
        """
        è‡ªåŠ¨æ£€æµ‹å¸‚åœºç±»å‹

        Returns:
            (secid, market_name)
        """
        symbol = symbol.upper().replace(" ", "")

        # å·²ç»å¸¦åç¼€çš„æƒ…å†µ
        if ".SH" in symbol:
            code = symbol.replace(".SH", "")
            return f"1.{code}", "Aè‚¡(ä¸Šæµ·)"
        elif ".SZ" in symbol:
            code = symbol.replace(".SZ", "")
            return f"0.{code}", "Aè‚¡(æ·±åœ³)"
        elif ".HK" in symbol:
            code = symbol.replace(".HK", "")
            return f"116.{code}", "æ¸¯è‚¡"

        # çº¯æ•°å­—ï¼Œè‡ªåŠ¨åˆ¤æ–­
        code = symbol.split(".")[0]
        if code.startswith("6"):
            return f"1.{code}", "Aè‚¡(ä¸Šæµ·)"
        elif code.startswith(("0", "3")):
            return f"0.{code}", "Aè‚¡(æ·±åœ³)"
        elif len(code) == 5:
            return f"116.{code}", "æ¸¯è‚¡"
        else:
            # é»˜è®¤å°è¯•ä¸Šæµ·
            return f"1.{code}", "Aè‚¡(ä¸Šæµ·)"

    async def execute(
        self,
        symbol: str,
        action: str = "quote",
        **kwargs
    ) -> Dict[str, Any]:
        """
        è·å–ä¸­å›½å¸‚åœºæ•°æ®

        Args:
            symbol: è‚¡ç¥¨ä»£ç  (å¦‚ 600519, 00700.HK)
            action: æ“ä½œç±»å‹
                - "quote": å®æ—¶è¡Œæƒ…
                - "kline": å†å²Kçº¿
                - "finance": è´¢åŠ¡æ•°æ®
                - "info": å…¬å¸èµ„æ–™
            **kwargs:
                - period: Kçº¿å‘¨æœŸ (daily/weekly/monthly)
                - limit: Kçº¿æ•°é‡é™åˆ¶
                - report_type: è´¢åŠ¡æŠ¥è¡¨ç±»å‹ (income/balance/cashflow)

        Returns:
            å¸‚åœºæ•°æ®
        """
        secid, market_name = self._detect_market(symbol)

        try:
            if action == "quote":
                return await self._get_quote(secid, symbol, market_name)
            elif action == "kline":
                period = kwargs.get("period", "daily")
                limit = kwargs.get("limit", 60)
                return await self._get_kline(secid, symbol, market_name, period, limit)
            elif action == "finance":
                return await self._get_finance(symbol, market_name)
            elif action == "info":
                return await self._get_company_info(symbol, market_name)
            else:
                return {
                    "success": False,
                    "error": f"ä¸æ”¯æŒçš„æ“ä½œç±»å‹: {action}",
                    "summary": f"è¯·ä½¿ç”¨ quote/kline/finance/info ä¹‹ä¸€"
                }

        except Exception as e:
            print(f"[ChinaMarketDataTool] Error: {e}")
            return {
                "success": False,
                "error": str(e),
                "summary": f"è·å–{symbol}æ•°æ®æ—¶å‡ºé”™: {str(e)}"
            }

    async def _get_quote(self, secid: str, symbol: str, market_name: str) -> Dict[str, Any]:
        """è·å–å®æ—¶è¡Œæƒ…"""
        params = {
            "secid": secid,
            "fields": "f43,f44,f45,f46,f47,f48,f50,f51,f52,f55,f57,f58,f60,f71,f116,f117,f162,f167,f168,f169,f170"
        }

        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.get(self.eastmoney_quote_url, params=params)
            response.raise_for_status()
            data = response.json()

            if data.get("data") is None:
                return {
                    "success": False,
                    "summary": f"æœªæ‰¾åˆ°è‚¡ç¥¨ {symbol} çš„è¡Œæƒ…æ•°æ®ï¼Œè¯·æ£€æŸ¥ä»£ç æ˜¯å¦æ­£ç¡®"
                }

            d = data["data"]

            # è§£ææ•°æ® (ä¸œæ–¹è´¢å¯Œè¿”å›çš„æ˜¯æ•´æ•°ï¼Œéœ€è¦é™¤ä»¥ç›¸åº”å€æ•°)
            current_price = d.get("f43", 0) / 100 if d.get("f43") else 0
            change = d.get("f169", 0) / 100 if d.get("f169") else 0
            change_pct = d.get("f170", 0) / 100 if d.get("f170") else 0
            high = d.get("f44", 0) / 100 if d.get("f44") else 0
            low = d.get("f45", 0) / 100 if d.get("f45") else 0
            open_price = d.get("f46", 0) / 100 if d.get("f46") else 0
            prev_close = d.get("f60", 0) / 100 if d.get("f60") else 0
            volume = d.get("f47", 0)  # æˆäº¤é‡ï¼ˆæ‰‹ï¼‰
            amount = d.get("f48", 0)  # æˆäº¤é¢
            market_cap = d.get("f116", 0)  # æ€»å¸‚å€¼
            float_cap = d.get("f117", 0)  # æµé€šå¸‚å€¼
            pe_ratio = d.get("f162", 0) / 100 if d.get("f162") else 0  # å¸‚ç›ˆç‡
            pb_ratio = d.get("f167", 0) / 100 if d.get("f167") else 0  # å¸‚å‡€ç‡
            name = d.get("f58", symbol)

            # æ ¼å¼åŒ–å¸‚å€¼
            def format_cap(cap):
                if cap >= 100000000:
                    return f"{cap / 100000000:.2f}äº¿"
                elif cap >= 10000:
                    return f"{cap / 10000:.2f}ä¸‡"
                return str(cap)

            summary = f"""ã€{name}({symbol})ã€‘{market_name} å®æ—¶è¡Œæƒ…

å½“å‰ä»·æ ¼: {current_price:.2f}
æ¶¨è·Œé¢: {change:+.2f}
æ¶¨è·Œå¹…: {change_pct:+.2f}%

ä»Šå¼€: {open_price:.2f}  |  æ˜¨æ”¶: {prev_close:.2f}
æœ€é«˜: {high:.2f}  |  æœ€ä½: {low:.2f}

æˆäº¤é‡: {volume:,}æ‰‹
æˆäº¤é¢: {format_cap(amount)}

æ€»å¸‚å€¼: {format_cap(market_cap)}
æµé€šå¸‚å€¼: {format_cap(float_cap)}

PE(å¸‚ç›ˆç‡): {pe_ratio:.2f}
PB(å¸‚å‡€ç‡): {pb_ratio:.2f}
"""

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "symbol": symbol,
                    "name": name,
                    "market": market_name,
                    "current_price": current_price,
                    "change": change,
                    "change_pct": change_pct,
                    "open": open_price,
                    "high": high,
                    "low": low,
                    "prev_close": prev_close,
                    "volume": volume,
                    "amount": amount,
                    "market_cap": market_cap,
                    "float_cap": float_cap,
                    "pe_ratio": pe_ratio,
                    "pb_ratio": pb_ratio
                }
            }

    async def _get_kline(
        self,
        secid: str,
        symbol: str,
        market_name: str,
        period: str = "daily",
        limit: int = 60
    ) -> Dict[str, Any]:
        """è·å–Kçº¿æ•°æ®"""
        # æ˜ å°„å‘¨æœŸ
        klt_map = {"daily": 101, "weekly": 102, "monthly": 103}
        klt = klt_map.get(period, 101)

        params = {
            "secid": secid,
            "fields1": "f1,f2,f3,f4,f5,f6",
            "fields2": "f51,f52,f53,f54,f55,f56,f57,f58,f59,f60,f61",
            "klt": klt,
            "fqt": 1,  # å‰å¤æƒ
            "lmt": limit
        }

        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.get(self.eastmoney_kline_url, params=params)
            response.raise_for_status()
            data = response.json()

            if data.get("data") is None or not data["data"].get("klines"):
                return {
                    "success": False,
                    "summary": f"æœªæ‰¾åˆ° {symbol} çš„Kçº¿æ•°æ®"
                }

            klines = data["data"]["klines"]
            name = data["data"].get("name", symbol)

            # è§£æKçº¿æ•°æ®
            parsed_klines = []
            for kline in klines[-limit:]:
                parts = kline.split(",")
                if len(parts) >= 7:
                    parsed_klines.append({
                        "date": parts[0],
                        "open": float(parts[1]),
                        "close": float(parts[2]),
                        "high": float(parts[3]),
                        "low": float(parts[4]),
                        "volume": int(parts[5]),
                        "amount": float(parts[6]),
                        "change_pct": float(parts[8]) if len(parts) > 8 else 0
                    })

            # è®¡ç®—ç®€å•ç»Ÿè®¡
            if parsed_klines:
                closes = [k["close"] for k in parsed_klines]
                latest = parsed_klines[-1]
                earliest = parsed_klines[0]
                period_return = ((latest["close"] - earliest["close"]) / earliest["close"]) * 100

                summary = f"""ã€{name}({symbol})ã€‘{market_name} Kçº¿æ•°æ® ({period})

æ•°æ®èŒƒå›´: {earliest["date"]} ~ {latest["date"]}
æ•°æ®æ¡æ•°: {len(parsed_klines)}æ¡

æœ€æ–°ä»·æ ¼: {latest["close"]:.2f}
åŒºé—´æ¶¨è·Œ: {period_return:+.2f}%
åŒºé—´æœ€é«˜: {max(closes):.2f}
åŒºé—´æœ€ä½: {min(closes):.2f}

æœ€è¿‘5æ—¥:
"""
                for k in parsed_klines[-5:]:
                    summary += f"  {k['date']}: å¼€{k['open']:.2f} æ”¶{k['close']:.2f} æ¶¨è·Œ{k['change_pct']:+.2f}%\n"
            else:
                summary = f"æœªæ‰¾åˆ° {symbol} çš„æœ‰æ•ˆKçº¿æ•°æ®"

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "symbol": symbol,
                    "name": name,
                    "market": market_name,
                    "period": period,
                    "klines": parsed_klines
                }
            }

    async def _get_finance(self, symbol: str, market_name: str) -> Dict[str, Any]:
        """è·å–è´¢åŠ¡æ•°æ® - ä½¿ç”¨æ–°æµªè´¢ç»ä½œä¸ºå¤‡é€‰"""
        # ç®€åŒ–ç‰ˆï¼šä½¿ç”¨ä¸œæ–¹è´¢å¯Œç½‘é¡µæ¥å£è·å–åŸºæœ¬è´¢åŠ¡æ•°æ®
        code = symbol.replace(".SH", "").replace(".SZ", "").replace(".HK", "")

        # æ„å»ºæ–°æµªè´¢ç»æ¥å£
        if "æ¸¯" in market_name:
            sina_url = f"http://hq.sinajs.cn/list=hk{code}"
        else:
            prefix = "sh" if symbol.endswith(".SH") or code.startswith("6") else "sz"
            sina_url = f"http://hq.sinajs.cn/list={prefix}{code}"

        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(
                    sina_url,
                    headers={"Referer": "http://finance.sina.com.cn"}
                )
                response.raise_for_status()

                # è§£ææ–°æµªè¿”å›çš„æ•°æ®
                content = response.text
                if "=" in content:
                    data_str = content.split("=")[1].strip().strip('"').strip(";")
                    if data_str:
                        parts = data_str.split(",")
                        if len(parts) > 30:
                            name = parts[0]
                            current = float(parts[3]) if parts[3] else 0

                            summary = f"""ã€{name}({symbol})ã€‘{market_name} è´¢åŠ¡æ¦‚è¦

âš ï¸ æ³¨æ„: è¯¦ç»†è´¢åŠ¡æŠ¥è¡¨å»ºè®®è®¿é—®ä¸œæ–¹è´¢å¯Œæˆ–åŒèŠ±é¡ºæŸ¥çœ‹

å½“å‰è‚¡ä»·: {current:.2f}
ä»Šæ—¥æˆäº¤é‡: {parts[8]}æ‰‹
ä»Šæ—¥æˆäº¤é¢: {float(parts[9])/100000000:.2f}äº¿

æç¤º: å¦‚éœ€å®Œæ•´è´¢åŠ¡æŠ¥è¡¨ï¼ˆèµ„äº§è´Ÿå€ºè¡¨ã€åˆ©æ¶¦è¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰ï¼Œ
å»ºè®®ä½¿ç”¨ tavily_search æœç´¢ "{name} è´¢åŠ¡æŠ¥è¡¨ å¹´æŠ¥" è·å–æ›´è¯¦ç»†ä¿¡æ¯ã€‚
"""
                            return {
                                "success": True,
                                "summary": summary,
                                "data": {"symbol": symbol, "name": name}
                            }

                return {
                    "success": False,
                    "summary": f"æ— æ³•è·å– {symbol} çš„è´¢åŠ¡æ•°æ®ï¼Œå»ºè®®ä½¿ç”¨æœç´¢å·¥å…·æŸ¥è¯¢"
                }

        except Exception as e:
            return {
                "success": False,
                "summary": f"è·å–è´¢åŠ¡æ•°æ®å‡ºé”™: {str(e)}ï¼Œå»ºè®®ä½¿ç”¨ tavily_search æœç´¢ç›¸å…³è´¢æŠ¥ä¿¡æ¯"
            }

    async def _get_company_info(self, symbol: str, market_name: str) -> Dict[str, Any]:
        """è·å–å…¬å¸åŸºæœ¬èµ„æ–™"""
        code = symbol.replace(".SH", "").replace(".SZ", "").replace(".HK", "")

        # ä½¿ç”¨ä¸œæ–¹è´¢å¯Œå…¬å¸èµ„æ–™æ¥å£
        if "æ¸¯" not in market_name:
            # Aè‚¡
            market_code = "SH" if code.startswith("6") else "SZ"
            info_url = f"http://emweb.securities.eastmoney.com/PC_HSF10/CompanySurvey/CompanySurveyAjax?code={market_code}{code}"
        else:
            # æ¸¯è‚¡ä¿¡æ¯è¾ƒéš¾è·å–ï¼Œè¿”å›æç¤º
            return {
                "success": True,
                "summary": f"""ã€{symbol}ã€‘æ¸¯è‚¡å…¬å¸èµ„æ–™

æ¸¯è‚¡å…¬å¸è¯¦ç»†èµ„æ–™å»ºè®®é€šè¿‡ä»¥ä¸‹æ–¹å¼è·å–:
1. ä½¿ç”¨ tavily_search æœç´¢ "{symbol} å…¬å¸ç®€ä»‹"
2. è®¿é—®æ¸¯äº¤æ‰€å®˜ç½‘æˆ–ä¸œæ–¹è´¢å¯Œæ¸¯è‚¡é¢‘é“
""",
                "data": {"symbol": symbol, "market": market_name}
            }

        try:
            async with httpx.AsyncClient(timeout=10.0) as client:
                response = await client.get(info_url)
                response.raise_for_status()
                data = response.json()

                if data.get("Result") and data.get("jbzl"):
                    info = data["jbzl"]

                    summary = f"""ã€{info.get('gsmc', symbol)}ã€‘å…¬å¸èµ„æ–™

è‚¡ç¥¨ä»£ç : {symbol} ({market_name})
å…¬å¸å…¨ç§°: {info.get('gsmc', 'N/A')}
è‹±æ–‡åç§°: {info.get('ywmc', 'N/A')}
æ›¾ç”¨å: {info.get('cym', 'N/A')}

æ‰€å±è¡Œä¸š: {info.get('sshy', 'N/A')}
æ‰€å±æ¿å—: {info.get('ssbk', 'N/A')}
ä¸Šå¸‚æ—¥æœŸ: {info.get('ssrq', 'N/A')}
ä¸Šå¸‚äº¤æ˜“æ‰€: {info.get('ssjys', 'N/A')}

æ³¨å†Œèµ„æœ¬: {info.get('zczb', 'N/A')}
æ³•å®šä»£è¡¨äºº: {info.get('frdb', 'N/A')}
è‘£äº‹é•¿: {info.get('dsz', 'N/A')}
æ€»ç»ç†: {info.get('zjl', 'N/A')}
è‘£ç§˜: {info.get('dm', 'N/A')}

æ³¨å†Œåœ°å€: {info.get('zcdz', 'N/A')}
åŠå…¬åœ°å€: {info.get('bgdz', 'N/A')}
å…¬å¸ç½‘å€: {info.get('gswz', 'N/A')}
ç”µå­é‚®ç®±: {info.get('dzyx', 'N/A')}

ä¸»è¥ä¸šåŠ¡:
{info.get('zyyw', 'N/A')}
"""
                    return {
                        "success": True,
                        "summary": summary,
                        "data": info
                    }
                else:
                    return {
                        "success": False,
                        "summary": f"æœªæ‰¾åˆ° {symbol} çš„å…¬å¸èµ„æ–™"
                    }

        except Exception as e:
            return {
                "success": False,
                "summary": f"è·å–å…¬å¸èµ„æ–™å‡ºé”™: {str(e)}"
            }

    def to_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "symbol": {
                        "type": "string",
                        "description": "Stock code, e.g., 600519 (Kweichow Moutai), 00700.HK (Tencent)"
                    },
                    "action": {
                        "type": "string",
                        "description": "Action type: quote(real-time quotes), kline(K-line), finance(financials), info(company info)",
                        "enum": ["quote", "kline", "finance", "info"],
                        "default": "quote"
                    },
                    "period": {
                        "type": "string",
                        "description": "K-line period (only for action=kline)",
                        "enum": ["daily", "weekly", "monthly"],
                        "default": "daily"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "K-line count limit",
                        "default": 60
                    }
                },
                "required": ["symbol"]
            }
        }


# ==================== 2. ä¼æŸ¥æŸ¥/å¤©çœ¼æŸ¥å·¥å…· ====================

class CompanyRegistryTool(Tool):
    """
    Company Registry Information Tool

    Get company registration info, equity structure, and business status via public APIs
    Note: Uses free public data sources as Qichacha/Tianyancha APIs require payment
    """

    def __init__(self):
        super().__init__(
            name="company_registry",
            description="""Query company business registration information and background.

Features:
- Company basic info (registered capital, founding date, business scope, etc.)
- Shareholder information and equity structure
- Executive information
- Business abnormalities and legal litigation
- Related companies

Note: Currently uses public data sources. For more detailed info, recommend using with tavily_search.
"""
        )
        # ä½¿ç”¨å›½å®¶ä¼ä¸šä¿¡ç”¨ä¿¡æ¯å…¬ç¤ºç³»ç»Ÿçš„å…¬å¼€æ¥å£
        self.api_url = "https://www.tianyancha.com/search"  # éœ€è¦å®é™…é…ç½®

    async def execute(
        self,
        company_name: str,
        query_type: str = "basic",
        **kwargs
    ) -> Dict[str, Any]:
        """
        æŸ¥è¯¢ä¼ä¸šä¿¡æ¯

        Args:
            company_name: å…¬å¸åç§°
            query_type: æŸ¥è¯¢ç±»å‹
                - basic: åŸºæœ¬ä¿¡æ¯
                - shareholders: è‚¡ä¸œä¿¡æ¯
                - executives: é«˜ç®¡ä¿¡æ¯
                - legal: æ³•å¾‹è¯‰è®¼
                - related: å…³è”ä¼ä¸š
        """
        try:
            # ç”±äºä¼æŸ¥æŸ¥/å¤©çœ¼æŸ¥éœ€è¦ä»˜è´¹APIï¼Œè¿™é‡Œæä¾›ä¸€ä¸ªæ™ºèƒ½æœç´¢æ–¹æ¡ˆ
            # å®é™…ä½¿ç”¨æ—¶å¯ä»¥æ›¿æ¢ä¸ºçœŸå®API

            search_queries = {
                "basic": f"{company_name} å…¬å¸ æ³¨å†Œèµ„æœ¬ æˆç«‹æ—¥æœŸ ç»è¥èŒƒå›´",
                "shareholders": f"{company_name} è‚¡ä¸œ è‚¡æƒç»“æ„ æŒè‚¡æ¯”ä¾‹",
                "executives": f"{company_name} é«˜ç®¡ è‘£äº‹é•¿ CEO ç®¡ç†å±‚",
                "legal": f"{company_name} è¯‰è®¼ æ³•å¾‹çº çº· è¡Œæ”¿å¤„ç½š",
                "related": f"{company_name} å…³è”å…¬å¸ å­å…¬å¸ æ¯å…¬å¸ æŠ•èµ„"
            }

            query = search_queries.get(query_type, search_queries["basic"])

            # è°ƒç”¨Tavilyæœç´¢è·å–ä¼ä¸šä¿¡æ¯
            from .mcp_tools import TavilySearchTool
            tavily = TavilySearchTool()
            result = await tavily.execute(query=query, max_results=5)

            if result.get("success"):
                summary = f"""ã€{company_name}ã€‘ä¼ä¸šä¿¡æ¯æŸ¥è¯¢ ({query_type})

{result.get('summary', 'æœªæ‰¾åˆ°ç›¸å…³ä¿¡æ¯')}

---
æç¤º: å¦‚éœ€æ›´è¯¦ç»†çš„å·¥å•†ä¿¡æ¯ï¼Œå»ºè®®:
1. è®¿é—®å›½å®¶ä¼ä¸šä¿¡ç”¨ä¿¡æ¯å…¬ç¤ºç³»ç»Ÿ (http://www.gsxt.gov.cn)
2. ä½¿ç”¨ä¼æŸ¥æŸ¥/å¤©çœ¼æŸ¥ç­‰ä¸“ä¸šå¹³å°
"""
                return {
                    "success": True,
                    "summary": summary,
                    "data": result.get("results", []),
                    "query_type": query_type
                }
            else:
                return result

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "summary": f"æŸ¥è¯¢ä¼ä¸š {company_name} ä¿¡æ¯æ—¶å‡ºé”™: {str(e)}"
            }

    def to_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "company_name": {
                        "type": "string",
                        "description": "Company name"
                    },
                    "query_type": {
                        "type": "string",
                        "description": "Query type",
                        "enum": ["basic", "shareholders", "executives", "legal", "related"],
                        "default": "basic"
                    }
                },
                "required": ["company_name"]
            }
        }


# ==================== 3. GitHubåˆ†æå·¥å…· ====================

class GitHubAnalyzerTool(Tool):
    """
    GitHub Project Analysis Tool

    Analyze GitHub repository activity, code quality, contributors, etc.
    """

    def __init__(self):
        super().__init__(
            name="github_analyzer",
            description="""Analyze GitHub projects and organizations.

Features:
- Repository basic info (stars, forks, issues)
- Commit activity analysis
- Major contributors
- Code language distribution
- Recent update status

Use cases:
- Evaluate open source project activity
- Analyze technical team capabilities
- Verify technology claims
"""
        )
        self.api_base = "https://api.github.com"
        self.token = os.getenv("GITHUB_TOKEN", "")

    def _get_headers(self) -> dict:
        headers = {
            "Accept": "application/vnd.github.v3+json",
            "User-Agent": "Magellan-Agent"
        }
        if self.token:
            headers["Authorization"] = f"token {self.token}"
        return headers

    async def execute(
        self,
        repo: str = None,
        organization: str = None,
        action: str = "repo_info",
        **kwargs
    ) -> Dict[str, Any]:
        """
        åˆ†æGitHubé¡¹ç›®

        Args:
            repo: ä»“åº“åœ°å€ (æ ¼å¼: owner/repo æˆ–å®Œæ•´URL)
            organization: ç»„ç»‡åç§°
            action: æ“ä½œç±»å‹
                - repo_info: ä»“åº“ä¿¡æ¯
                - contributors: è´¡çŒ®è€…åˆ†æ
                - activity: æ´»è·ƒåº¦åˆ†æ
                - languages: è¯­è¨€åˆ†å¸ƒ
                - org_repos: ç»„ç»‡ä»“åº“åˆ—è¡¨
        """
        try:
            if action == "org_repos" and organization:
                return await self._get_org_repos(organization)
            elif repo:
                # è§£æä»“åº“åœ°å€
                if "github.com" in repo:
                    # ä»URLæå– owner/repo
                    parts = repo.rstrip("/").split("github.com/")[-1].split("/")
                    if len(parts) >= 2:
                        repo = f"{parts[0]}/{parts[1]}"

                if action == "repo_info":
                    return await self._get_repo_info(repo)
                elif action == "contributors":
                    return await self._get_contributors(repo)
                elif action == "activity":
                    return await self._get_activity(repo)
                elif action == "languages":
                    return await self._get_languages(repo)
                else:
                    return await self._get_repo_info(repo)
            else:
                return {
                    "success": False,
                    "summary": "è¯·æä¾›ä»“åº“åœ°å€(repo)æˆ–ç»„ç»‡åç§°(organization)"
                }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "summary": f"GitHubåˆ†æå‡ºé”™: {str(e)}"
            }

    async def _get_repo_info(self, repo: str) -> Dict[str, Any]:
        """è·å–ä»“åº“åŸºæœ¬ä¿¡æ¯"""
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.get(
                f"{self.api_base}/repos/{repo}",
                headers=self._get_headers()
            )

            if response.status_code == 404:
                return {
                    "success": False,
                    "summary": f"æœªæ‰¾åˆ°ä»“åº“: {repo}"
                }

            response.raise_for_status()
            data = response.json()

            # è·å–æœ€è¿‘æäº¤
            commits_resp = await client.get(
                f"{self.api_base}/repos/{repo}/commits",
                headers=self._get_headers(),
                params={"per_page": 5}
            )
            recent_commits = commits_resp.json() if commits_resp.status_code == 200 else []

            created = datetime.fromisoformat(data["created_at"].replace("Z", "+00:00"))
            updated = datetime.fromisoformat(data["updated_at"].replace("Z", "+00:00"))
            days_since_update = (datetime.now(updated.tzinfo) - updated).days

            summary = f"""ã€GitHubä»“åº“åˆ†æã€‘{data['full_name']}

ğŸ“Š åŸºæœ¬æŒ‡æ ‡:
  â­ Stars: {data['stargazers_count']:,}
  ğŸ´ Forks: {data['forks_count']:,}
  ğŸ‘ï¸ Watchers: {data['subscribers_count']:,}
  ğŸ› Open Issues: {data['open_issues_count']:,}

ğŸ“ é¡¹ç›®ä¿¡æ¯:
  æè¿°: {data.get('description', 'N/A')}
  ä¸»è¦è¯­è¨€: {data.get('language', 'N/A')}
  License: {data.get('license', {}).get('name', 'N/A') if data.get('license') else 'N/A'}

ğŸ“… æ—¶é—´çº¿:
  åˆ›å»ºæ—¶é—´: {created.strftime('%Y-%m-%d')}
  æœ€åæ›´æ–°: {updated.strftime('%Y-%m-%d')} ({days_since_update}å¤©å‰)

ğŸ”— é“¾æ¥:
  ä¸»é¡µ: {data.get('homepage', 'N/A')}
  ä»“åº“: {data['html_url']}
"""

            if recent_commits:
                summary += "\nğŸ“ æœ€è¿‘æäº¤:\n"
                for commit in recent_commits[:3]:
                    msg = commit['commit']['message'].split('\n')[0][:50]
                    author = commit['commit']['author']['name']
                    date = commit['commit']['author']['date'][:10]
                    summary += f"  - [{date}] {msg}... by {author}\n"

            # æ´»è·ƒåº¦è¯„ä¼°
            if days_since_update <= 7:
                activity_level = "ğŸŸ¢ éå¸¸æ´»è·ƒ"
            elif days_since_update <= 30:
                activity_level = "ğŸŸ¡ æ´»è·ƒ"
            elif days_since_update <= 90:
                activity_level = "ğŸŸ  ä¸€èˆ¬"
            else:
                activity_level = "ğŸ”´ ä¸æ´»è·ƒ"

            summary += f"\nğŸ“ˆ æ´»è·ƒåº¦è¯„ä¼°: {activity_level}"

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "name": data["name"],
                    "full_name": data["full_name"],
                    "description": data.get("description"),
                    "stars": data["stargazers_count"],
                    "forks": data["forks_count"],
                    "watchers": data["subscribers_count"],
                    "open_issues": data["open_issues_count"],
                    "language": data.get("language"),
                    "created_at": data["created_at"],
                    "updated_at": data["updated_at"],
                    "days_since_update": days_since_update,
                    "url": data["html_url"]
                }
            }

    async def _get_contributors(self, repo: str) -> Dict[str, Any]:
        """è·å–è´¡çŒ®è€…ä¿¡æ¯"""
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.get(
                f"{self.api_base}/repos/{repo}/contributors",
                headers=self._get_headers(),
                params={"per_page": 20}
            )

            if response.status_code != 200:
                return {"success": False, "summary": f"è·å–è´¡çŒ®è€…ä¿¡æ¯å¤±è´¥"}

            contributors = response.json()

            summary = f"ã€{repo}ã€‘è´¡çŒ®è€…åˆ†æ\n\n"
            summary += f"è´¡çŒ®è€…æ€»æ•°: {len(contributors)}+ äºº\n\n"
            summary += "Top 10 è´¡çŒ®è€…:\n"

            for i, c in enumerate(contributors[:10], 1):
                summary += f"  {i}. {c['login']} - {c['contributions']:,} commits\n"

            # è®¡ç®—è´¡çŒ®é›†ä¸­åº¦
            if contributors:
                total_commits = sum(c['contributions'] for c in contributors)
                top3_commits = sum(c['contributions'] for c in contributors[:3])
                concentration = (top3_commits / total_commits * 100) if total_commits > 0 else 0

                summary += f"\nğŸ“Š è´¡çŒ®é›†ä¸­åº¦: Top 3 è´¡çŒ®è€…å  {concentration:.1f}% çš„æäº¤"
                if concentration > 80:
                    summary += " (âš ï¸ é«˜åº¦ä¾èµ–å°‘æ•°å¼€å‘è€…)"
                elif concentration > 50:
                    summary += " (æ­£å¸¸)"
                else:
                    summary += " (âœ… è´¡çŒ®åˆ†å¸ƒå‡åŒ€)"

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "total": len(contributors),
                    "contributors": [
                        {"login": c["login"], "contributions": c["contributions"]}
                        for c in contributors[:20]
                    ]
                }
            }

    async def _get_activity(self, repo: str) -> Dict[str, Any]:
        """è·å–æ´»è·ƒåº¦åˆ†æ"""
        async with httpx.AsyncClient(timeout=15.0) as client:
            # è·å–æäº¤ç»Ÿè®¡
            stats_resp = await client.get(
                f"{self.api_base}/repos/{repo}/stats/commit_activity",
                headers=self._get_headers()
            )

            # è·å–æœ€è¿‘çš„issueså’ŒPRs
            issues_resp = await client.get(
                f"{self.api_base}/repos/{repo}/issues",
                headers=self._get_headers(),
                params={"state": "all", "per_page": 30}
            )

            summary = f"ã€{repo}ã€‘æ´»è·ƒåº¦åˆ†æ\n\n"

            if stats_resp.status_code == 200:
                stats = stats_resp.json()
                if stats:
                    # æœ€è¿‘4å‘¨æäº¤æ•°
                    recent_weeks = stats[-4:] if len(stats) >= 4 else stats
                    recent_commits = sum(week.get("total", 0) for week in recent_weeks)
                    summary += f"ğŸ“ˆ æœ€è¿‘4å‘¨æäº¤: {recent_commits} commits\n"

                    # å¹´åº¦æäº¤æ•°
                    yearly_commits = sum(week.get("total", 0) for week in stats)
                    summary += f"ğŸ“… å¹´åº¦æäº¤æ€»æ•°: {yearly_commits} commits\n"

            if issues_resp.status_code == 200:
                issues = issues_resp.json()
                open_issues = sum(1 for i in issues if i.get("state") == "open")
                closed_issues = sum(1 for i in issues if i.get("state") == "closed")
                prs = sum(1 for i in issues if i.get("pull_request"))

                summary += f"\nğŸ› Issues (æœ€è¿‘30æ¡):\n"
                summary += f"  - å¼€æ”¾: {open_issues}\n"
                summary += f"  - å·²å…³é—­: {closed_issues}\n"
                summary += f"  - PRæ•°é‡: {prs}\n"

            return {
                "success": True,
                "summary": summary,
                "data": {}
            }

    async def _get_languages(self, repo: str) -> Dict[str, Any]:
        """è·å–è¯­è¨€åˆ†å¸ƒ"""
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.get(
                f"{self.api_base}/repos/{repo}/languages",
                headers=self._get_headers()
            )

            if response.status_code != 200:
                return {"success": False, "summary": "è·å–è¯­è¨€åˆ†å¸ƒå¤±è´¥"}

            languages = response.json()
            total_bytes = sum(languages.values())

            summary = f"ã€{repo}ã€‘ä»£ç è¯­è¨€åˆ†å¸ƒ\n\n"

            for lang, bytes_count in sorted(languages.items(), key=lambda x: -x[1]):
                pct = (bytes_count / total_bytes * 100) if total_bytes > 0 else 0
                bar = "â–ˆ" * int(pct / 5)
                summary += f"  {lang}: {pct:.1f}% {bar}\n"

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "languages": languages,
                    "total_bytes": total_bytes
                }
            }

    async def _get_org_repos(self, org: str) -> Dict[str, Any]:
        """è·å–ç»„ç»‡çš„ä»“åº“åˆ—è¡¨"""
        async with httpx.AsyncClient(timeout=15.0) as client:
            response = await client.get(
                f"{self.api_base}/orgs/{org}/repos",
                headers=self._get_headers(),
                params={"sort": "stars", "per_page": 20}
            )

            if response.status_code == 404:
                return {"success": False, "summary": f"æœªæ‰¾åˆ°ç»„ç»‡: {org}"}

            response.raise_for_status()
            repos = response.json()

            summary = f"ã€GitHubç»„ç»‡ã€‘{org}\n\n"
            summary += f"å…¬å¼€ä»“åº“æ•°: {len(repos)}+\n\n"
            summary += "çƒ­é—¨ä»“åº“ (æŒ‰Starsæ’åº):\n"

            total_stars = 0
            for repo in repos[:10]:
                total_stars += repo["stargazers_count"]
                summary += f"  â­ {repo['stargazers_count']:,} - {repo['name']}\n"
                if repo.get("description"):
                    summary += f"      {repo['description'][:60]}...\n"

            summary += f"\nTop 10 ä»“åº“æ€» Stars: {total_stars:,}"

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "organization": org,
                    "repos": [
                        {
                            "name": r["name"],
                            "stars": r["stargazers_count"],
                            "description": r.get("description"),
                            "language": r.get("language")
                        }
                        for r in repos
                    ]
                }
            }

    def to_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "repo": {
                        "type": "string",
                        "description": "ä»“åº“åœ°å€ï¼Œæ ¼å¼: owner/repo æˆ–å®Œæ•´GitHub URL"
                    },
                    "organization": {
                        "type": "string",
                        "description": "GitHubç»„ç»‡åç§°"
                    },
                    "action": {
                        "type": "string",
                        "description": "æ“ä½œç±»å‹",
                        "enum": ["repo_info", "contributors", "activity", "languages", "org_repos"],
                        "default": "repo_info"
                    }
                }
            }
        }


# ==================== 4. ä¸“åˆ©æ£€ç´¢å·¥å…· ====================

class PatentSearchTool(Tool):
    """
    Patent Search Tool

    Search patent information via public APIs
    Supports: Google Patents, USPTO, CNIPA (China)
    """

    def __init__(self):
        super().__init__(
            name="patent_search",
            description="""Search and analyze patent information.

Features:
- Search patents by company/inventor
- Search technical patents by keywords
- View patent details
- Patent citation analysis

Supported patent offices:
- USPTO (United States)
- EPO (Europe)
- CNIPA (China)
- WIPO (World Intellectual Property Organization)
"""
        )

    async def execute(
        self,
        query: str,
        search_type: str = "keyword",
        patent_office: str = "all",
        limit: int = 10,
        **kwargs
    ) -> Dict[str, Any]:
        """
        æœç´¢ä¸“åˆ©

        Args:
            query: æœç´¢å†…å®¹ï¼ˆå…¬å¸å/å‘æ˜äºº/å…³é”®è¯ï¼‰
            search_type: æœç´¢ç±»å‹
                - keyword: å…³é”®è¯æœç´¢
                - assignee: æŒ‰ä¸“åˆ©æŒæœ‰äººæœç´¢
                - inventor: æŒ‰å‘æ˜äººæœç´¢
            patent_office: ä¸“åˆ©å±€ (all/USPTO/EPO/CNIPA)
            limit: è¿”å›æ•°é‡é™åˆ¶
        """
        try:
            # ä½¿ç”¨Google Patentsæœç´¢ï¼ˆé€šè¿‡Tavilyä»£ç†ï¼‰
            # æ„å»ºä¸“ä¸šçš„ä¸“åˆ©æœç´¢æŸ¥è¯¢
            if search_type == "assignee":
                search_query = f"site:patents.google.com {query} assignee patent"
            elif search_type == "inventor":
                search_query = f"site:patents.google.com inventor:{query} patent"
            else:
                search_query = f"site:patents.google.com {query} patent"

            if patent_office != "all":
                office_map = {
                    "USPTO": "US patent",
                    "EPO": "EP patent",
                    "CNIPA": "CN patent",
                    "WIPO": "WO patent"
                }
                search_query += f" {office_map.get(patent_office, '')}"

            # è°ƒç”¨Tavilyæœç´¢ä¸“åˆ©ä¿¡æ¯
            from .mcp_tools import TavilySearchTool
            tavily = TavilySearchTool()
            result = await tavily.execute(query=search_query, max_results=limit)

            if result.get("success"):
                # è§£æä¸“åˆ©ä¿¡æ¯
                patents = []
                for res in result.get("results", []):
                    url = res.get("url", "")
                    if "patents.google.com" in url:
                        patents.append({
                            "title": res.get("title", ""),
                            "url": url,
                            "snippet": res.get("content", "")[:200]
                        })

                summary = f"""ã€ä¸“åˆ©æœç´¢ç»“æœã€‘æŸ¥è¯¢: {query}

æœç´¢ç±»å‹: {search_type}
ä¸“åˆ©å±€èŒƒå›´: {patent_office}
æ‰¾åˆ°ä¸“åˆ©: {len(patents)} æ¡

"""
                for i, p in enumerate(patents[:limit], 1):
                    summary += f"{i}. {p['title']}\n"
                    summary += f"   {p['snippet']}...\n"
                    summary += f"   é“¾æ¥: {p['url']}\n\n"

                if not patents:
                    summary += "æœªæ‰¾åˆ°ç›¸å…³ä¸“åˆ©ï¼Œå»ºè®®:\n"
                    summary += "1. å°è¯•ä¸åŒçš„å…³é”®è¯\n"
                    summary += "2. ä½¿ç”¨è‹±æ–‡æœç´¢å¯èƒ½è·å¾—æ›´å¤šç»“æœ\n"
                    summary += "3. ç›´æ¥è®¿é—® patents.google.com æœç´¢\n"

                return {
                    "success": True,
                    "summary": summary,
                    "data": {
                        "query": query,
                        "search_type": search_type,
                        "patents": patents
                    }
                }
            else:
                return result

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "summary": f"ä¸“åˆ©æœç´¢å‡ºé”™: {str(e)}"
            }

    def to_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "query": {
                        "type": "string",
                        "description": "æœç´¢å†…å®¹ï¼ˆå…¬å¸åã€å‘æ˜äººåæˆ–æŠ€æœ¯å…³é”®è¯ï¼‰"
                    },
                    "search_type": {
                        "type": "string",
                        "description": "æœç´¢ç±»å‹",
                        "enum": ["keyword", "assignee", "inventor"],
                        "default": "keyword"
                    },
                    "patent_office": {
                        "type": "string",
                        "description": "ä¸“åˆ©å±€èŒƒå›´",
                        "enum": ["all", "USPTO", "EPO", "CNIPA", "WIPO"],
                        "default": "all"
                    },
                    "limit": {
                        "type": "integer",
                        "description": "è¿”å›æ•°é‡é™åˆ¶",
                        "default": 10
                    }
                },
                "required": ["query"]
            }
        }


# ==================== 5. èˆ†æƒ…ç›‘æ§å·¥å…· ====================

class SentimentMonitorTool(Tool):
    """
    Sentiment Monitoring Tool

    Monitor online sentiment for companies/projects, identify negative news and risk signals
    """

    def __init__(self):
        super().__init__(
            name="sentiment_monitor",
            description="""Monitor target company or project's online sentiment.

Features:
- Negative news tracking
- Social media sentiment analysis
- Risk signal identification
- Popularity trend analysis

Use cases:
- Sentiment check during investment due diligence
- Risk monitoring for portfolio companies
- Industry negative event tracking
"""
        )

    async def execute(
        self,
        target: str,
        monitor_type: str = "comprehensive",
        time_range: str = "week",
        focus_areas: List[str] = None,
        **kwargs
    ) -> Dict[str, Any]:
        """
        Monitor sentiment for a target

        Args:
            target: Monitoring target (company name/project name/person name)
            monitor_type: Monitoring type
                - comprehensive: Comprehensive sentiment
                - negative: Negative news
                - social: Social media
                - regulatory: Regulatory updates
            time_range: Time range (day/week/month)
            focus_areas: Focus areas (e.g. ["financial fraud", "executive departure", "litigation"])
        """
        try:
            results = {
                "negative_news": [],
                "regulatory_news": [],
                "social_sentiment": {},
                "risk_signals": []
            }

            # Build search query
            from .mcp_tools import TavilySearchTool
            tavily = TavilySearchTool()

            # 1. Negative news search
            negative_keywords = [
                "negative", "problem", "risk", "investigation", "penalty", "lawsuit", "layoff",
                "loss", "decline", "scandal", "violation", "fraud", "controversy"
            ]

            if monitor_type in ["comprehensive", "negative"]:
                neg_query = f"{target} ({' OR '.join(negative_keywords[:5])})"
                neg_result = await tavily.execute(
                    query=neg_query,
                    topic="news",
                    time_range=time_range,
                    max_results=5
                )
                if neg_result.get("success"):
                    results["negative_news"] = neg_result.get("results", [])

            # 2. Regulatory updates search
            if monitor_type in ["comprehensive", "regulatory"]:
                reg_query = f"{target} (regulatory OR penalty OR investigation OR compliance OR notice)"
                reg_result = await tavily.execute(
                    query=reg_query,
                    topic="news",
                    time_range=time_range,
                    max_results=5
                )
                if reg_result.get("success"):
                    results["regulatory_news"] = reg_result.get("results", [])

            # 3. Specific focus areas
            if focus_areas:
                for area in focus_areas[:3]:
                    area_result = await tavily.execute(
                        query=f"{target} {area}",
                        topic="news",
                        time_range=time_range,
                        max_results=3
                    )
                    if area_result.get("success") and area_result.get("results"):
                        results["risk_signals"].append({
                            "area": area,
                            "news": area_result.get("results", [])
                        })

            # Generate sentiment report
            time_range_label = {"day": "24 hours", "week": "1 week", "month": "1 month"}.get(time_range, time_range)
            summary = f"""ã€Sentiment Monitoring Reportã€‘{target}

ğŸ“… Monitoring Period: Last {time_range_label}
ğŸ“Š Monitoring Type: {monitor_type}

"""

            # Negative news summary
            neg_count = len(results["negative_news"])
            summary += f"ğŸ”´ Negative News: Found {neg_count} items\n"
            if results["negative_news"]:
                for i, news in enumerate(results["negative_news"][:3], 1):
                    summary += f"   {i}. {news.get('title', 'N/A')}\n"
                    summary += f"      Source: {news.get('url', 'N/A')}\n"
            else:
                summary += "   No significant negative news found âœ…\n"

            # Regulatory updates summary
            reg_count = len(results["regulatory_news"])
            summary += f"\nâš–ï¸ Regulatory Updates: Found {reg_count} items\n"
            if results["regulatory_news"]:
                for i, news in enumerate(results["regulatory_news"][:3], 1):
                    summary += f"   {i}. {news.get('title', 'N/A')}\n"
            else:
                summary += "   No regulatory-related news found âœ…\n"

            # Risk signals
            if results["risk_signals"]:
                summary += f"\nâš ï¸ Focus Areas:\n"
                for signal in results["risk_signals"]:
                    summary += f"   ã€{signal['area']}ã€‘: {len(signal['news'])} related news items\n"

            # Risk assessment
            total_negative = neg_count + reg_count + sum(len(s["news"]) for s in results["risk_signals"])
            if total_negative == 0:
                risk_level = "ğŸŸ¢ Low Risk - No significant negative sentiment found"
            elif total_negative <= 3:
                risk_level = "ğŸŸ¡ Low-Medium Risk - Some negative information exists"
            elif total_negative <= 7:
                risk_level = "ğŸŸ  Medium Risk - Multiple negative items, requires attention"
            else:
                risk_level = "ğŸ”´ High Risk - Dense negative sentiment, recommend in-depth investigation"

            summary += f"\nğŸ“ˆ Sentiment Risk Assessment: {risk_level}\n"
            summary += f"   Total Negative Items: {total_negative}\n"

            return {
                "success": True,
                "summary": summary,
                "data": {
                    "target": target,
                    "time_range": time_range,
                    "negative_count": neg_count,
                    "regulatory_count": reg_count,
                    "total_negative": total_negative,
                    "results": results
                }
            }

        except Exception as e:
            return {
                "success": False,
                "error": str(e),
                "summary": f"Sentiment monitoring error: {str(e)}"
            }

    def to_schema(self) -> Dict[str, Any]:
        return {
            "name": self.name,
            "description": self.description,
            "parameters": {
                "type": "object",
                "properties": {
                    "target": {
                        "type": "string",
                        "description": "Monitoring target (company name/project name/person name)"
                    },
                    "monitor_type": {
                        "type": "string",
                        "description": "Monitoring type",
                        "enum": ["comprehensive", "negative", "social", "regulatory"],
                        "default": "comprehensive"
                    },
                    "time_range": {
                        "type": "string",
                        "description": "Time range",
                        "enum": ["day", "week", "month"],
                        "default": "week"
                    },
                    "focus_areas": {
                        "type": "array",
                        "items": {"type": "string"},
                        "description": "Focus areas, e.g. ['financial fraud', 'executive departure']"
                    }
                },
                "required": ["target"]
            }
        }


# ==================== Export Tool List ====================

__all__ = [
    "ChinaMarketDataTool",
    "CompanyRegistryTool",
    "GitHubAnalyzerTool",
    "PatentSearchTool",
    "SentimentMonitorTool"
]
